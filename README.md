# Medical-chatbot
Medical chatbot using mistral llm

I have used ollam tool to download this llm and run it in background and using ollama api localy connect it to the main python app 
while runnign the app the local api sends and recieve the request from the app 

The context length is downgraded to 160 for less memory usage ,If want it can upgraded based on the user needs 

By specifying prompt in python code the mistral model will perform the medical related response well rather than a simple quick responding chatbot can be used for various purpose other than medical response 
